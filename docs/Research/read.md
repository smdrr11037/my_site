# 文献阅读

> 这里是论文的阅读记录


## Benchmarking Large Language Models as AI Research Agents

> GPT 找的2024会议盲审的 pdf，所以不知道作者是谁

* 让 LLM 执行训练机器学习 AI 的任务
* 用训练出的 AI 
    * 在相应数据集上的准确率
    * LLM 怎么得到结果
    * 用时，这三点来评价效果
*  MLAgentBench - 作者搭建的让 LLM 能获取任务、执行代码、评测结果的框架（重点
*  结果：90% 的任务有性能提升，平均提升率 45%
*  AI 的可靠性和鲁棒性有待提高

---------------

## LARGE LANGUAGE MODELS AS GAMING AGENTS

> 也是 GPT 找的盲审（所以通过审核了吗

* 两个游戏：井字棋和德州扑克 - 完全信息游戏和不完全信息游戏（可以轻易判断输赢、生成过程
* 结果 - 大模型只比随机智能体好一点
* 本文揭示 LLM 不能在游戏中表现好的原因
    * LLM lack gaming intents（不能 think ahead
    * LLM suffer from hallucinations（幻觉）和事实错误（意识不到输赢

> 我试了，是真的（GPT 下井字棋下不过我


* 因此作者提出了一个 Think Ahead Language powered Gaming Agent (TALAGA).（这缩写比好多单词长吧
    * 递归地预测对手行为
    * 给预测的状态 reward signals
    * 回溯到当前状态，根据 reward signals 选择行为
    * outperforms ToT by 21%, CoT-SC by 17%, and CoT by 29% 
* 指出用 Game 测评 LLM 可以 push 它突破限制
* 不足之处
    * 考虑情况太少，只用了 GPT（其他大模型、其他游戏



----------------



## Robust agents learn causal world models

> Jonathan Richens - Google DeepMind &Tom Everitt Google DeepMind
>
> （怎么就一个人

* 问题：因果推理在大模型的泛化中是否是必须的
* 作者的回答：在大量分布转移下能够满足遗憾界限的任何代理程序，必须已经学习了数据生成过程的近似因果模型（？感觉不是人类的语言了这个）


## 语音辅助的唇语识别研究

> 赵雅的博士学位论文

主要成果

* 初期 - 建立大规模普通话唇语数据集
* 唇语多义性 - 蒸馏语音辅助知识提升准确性
* 引入语音模态辅助信息带来的模态间异质性难题 - 基于语音与视频模态的上下文相关性，提升语音辅助唇语识别模型的准确性
* 说话人的身份和姿态 - 跨模态自监督预训练方法、“聚类-替换”操作解耦

## 一些概念记录

* 唇语识别系统包含 3 个组成部分：唇部定位、视觉特征提取和序列建模
* 理想的唇部视觉特征：
    * 对噪声和环境变化（照明、变形、运动等）鲁棒；
    * 可辨别性强，即不同类别之间的特征应该是可区分的，相同类别之间的特征应该尽可能相似；
    * 特征数量和维度尽量少，但必须保证能代表说话人的内容；
    * 独立于说话人。
* 特征提取方法
    * 传统技术：基于像素的方法（低层）、基于形状的方法（ACM、高层）和混合特征方法（AAM）
    * 深度学习：基于卷积神经网络（CNN，2D-动态特征图像、3D-加上时序）
* 序列建模
    * 基于循环神经网路 - Seq2Seq 模型，注意力改善信息完整性，连接主义时序分类模型改善对齐
    * 基于 Transformer - 也是 Seq2Seq 模型，自注意力机制计算特征（比 Bi-LSTM 效果更好
    * 基于时间卷积网络

* 知识蒸馏 - 将一个模型学到的知识转移到另一个模型
    * 基于标签（标签知识通常是指模型最后一层输出的、位于 softmax 前的特征，也就是 logits 概率分布
        * 简单易懂，但无法获得中间层的监督信息（有时很重要
    * 基于隐藏层特征 - “因素”
    * 基于关系（特征图之间的内积来衡量这一对特征图之间的关系

* 自监督学习 - 机器根据观察到的部分输入，预测该输入的任何部分
    * 生成式
    * 判别式

* 计划采样 - 在预测当前时间步的输出时，以一定概率采用前序时间步预测得到的标签作为输入
* 文章所用方法利用表示输入和输出序列之间对齐关系的编码器-解码器注意力分布计算跨模态变换矩阵

### 阅读中遇到的问题

* 一系列自监督模型的解释没看懂
* transformer 不太搞得懂


## AUTO-AVSR: AUDIO-VISUAL SPEECH RECOGNITION WITH AUTOMATIC LABELS

* 人工标注数据集昂贵，用已有的准确度高的语音识别模型扩充所需的数据集，得到了很好的训练效果
* 跑了 github 上的代码
